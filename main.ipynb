{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import os\n",
    "from bing_image_downloader import downloader\n",
    "import cv2\n",
    "import imghdr\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "import random\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downloader.download(\"Hagia Sophia — Istanbul, Turkey\", limit=250, output_dir=\"images\")\n",
    "# downloader.download(\"Dancing House — Prague, Czech Republic\", limit=250, output_dir=\"images\")\n",
    "# downloader.download(\"Château de Chenonceau — Chenonceaux, France\", limit=250, output_dir=\"images\")\n",
    "# downloader.download(\"The Colosseum — Rome, Italy\", limit=250, output_dir=\"images\")\n",
    "# downloader.download(\"St. Basil’s Cathedral — Moscow, Russia\", limit=250, output_dir=\"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"images\"\n",
    "image_exts = [\"jpeg\", \"jpg\", \"bmp\", \"png\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.listdir(os.path.join(data_dir,\"Chateau de Chenonceau\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(os.path.join(data_dir, \"Chateau de Chenonceau\", \"Image_10.jpg\"))\n",
    "# plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))\n",
    "# plt.show()\n",
    "# img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    labels=\"inferred\",\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,   \n",
    ")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_iterator = data.as_numpy_iterator()\n",
    "data_iterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = data_iterator.next()\n",
    "len(batch)\n",
    "batch[0].shape, batch[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fig, ax = plt.subplots(ncols=10, figsize=(20,20))\n",
    "# for idx, img in enumerate(batch[0][:10]):\n",
    "#   ax[idx].imshow(img.astype(int))\n",
    "#   ax[idx].title.set_text(batch[1][idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    labels=\"inferred\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"training\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    ")\n",
    "val_test_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    labels=\"inferred\",\n",
    "    validation_split=0.3,\n",
    "    subset=\"validation\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,   \n",
    ")\n",
    "tf.data.experimental.cardinality(val_test_ds).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = val_test_ds.cardinality().numpy()\n",
    "val_num = int(0.7*total_samples)\n",
    "test_num = int(0.3*total_samples)\n",
    "val_num, test_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_ds = val_test_ds.take(val_num)\n",
    "test_ds = val_test_ds.skip(val_num).take(test_num)\n",
    "val_ds, test_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    \"images\",\n",
    "    labels=\"inferred\",\n",
    "    seed=123,\n",
    "    label_mode=\"categorical\",\n",
    "    image_size=(256, 256),\n",
    "    batch_size=32,\n",
    ")\n",
    "\n",
    "images_count_val = [0,0,0,0,0]\n",
    "images_count_test = [0,0,0,0,0]\n",
    "\n",
    "val__images = []\n",
    "val__labels = []\n",
    "\n",
    "test_images = []\n",
    "test_labels = []\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "\n",
    "for image,label in main_ds.unbatch():\n",
    "\n",
    "    if images_count_test[np.argmax(label.numpy())] < 85:\n",
    "        train_images.append(image)\n",
    "        train_labels.append(label)\n",
    "        images_count_test[np.argmax(label.numpy())] = images_count_test[np.argmax(label.numpy())] + 1\n",
    "\n",
    "    elif images_count_val[np.argmax(label.numpy())] < 15:\n",
    "        val__images.append(image)\n",
    "        val__labels.append(label)\n",
    "        images_count_val[np.argmax(label.numpy())] = images_count_val[np.argmax(label.numpy())] + 1\n",
    "    \n",
    "    else:\n",
    "        test_images.append(image)\n",
    "        test_labels.append(label)\n",
    "\n",
    "train_ds_balanced = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "train_ds_balanced = train_ds_balanced.shuffle(100)\n",
    "train_ds_balanced = train_ds_balanced.batch(32)\n",
    "\n",
    "val_ds_balanced = tf.data.Dataset.from_tensor_slices((val__images, val__labels))\n",
    "val_ds_balanced = val_ds_balanced.shuffle(100)\n",
    "val_ds_balanced = val_ds_balanced.batch(32)\n",
    "\n",
    "test_ds_balanced = tf.data.Dataset.from_tensor_slices((test_images, test_labels))\n",
    "test_ds_balanced = test_ds_balanced.shuffle(100)\n",
    "test_ds_balanced = test_ds_balanced.batch(32)\n",
    "\n",
    "train_ds_balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class_counts = {}\n",
    "\n",
    "for _, labels in val_ds_balanced:\n",
    "    for label in labels.numpy():\n",
    "        class_idx = label.argmax()  \n",
    "        if class_idx not in class_counts:\n",
    "            class_counts[class_idx] = 1\n",
    "        else:\n",
    "            class_counts[class_idx] += 1\n",
    "\n",
    "for class_idx, count in class_counts.items():\n",
    "    print(f\"Class {class_idx}: {count} samples\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = tf.keras.Sequential(\n",
    "    [\n",
    "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),  # RandomFlip layer\n",
    "        tf.keras.layers.RandomTranslation(\n",
    "            height_factor=(-0.2, 0.3), width_factor=(-0.2, 0.3)\n",
    "        ),  # RandomTranslation layer\n",
    "        tf.keras.layers.RandomRotation(factor=0.2),  # RandomRotation layer\n",
    "        # tf.keras.layers.RandomZoom(height_factor=(0.2, 0.3)),  # RandomZoom layer\n",
    "        tf.keras.layers.RandomContrast(factor=(0.2)),  # RandomContrast layer\n",
    "        tf.keras.layers.RandomBrightness(factor=(0.2)),  # RandomBrightness layer\n",
    "    ]\n",
    ")\n",
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "train_ds_augmented = train_ds_balanced.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "train_ds_augmented2 = train_ds_balanced.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "train_ds_augmented3 = train_ds_balanced.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE\n",
    ")\n",
    "train_ds_augmented4 = train_ds_balanced.map(\n",
    "    lambda x, y: (data_augmentation(x, training=True), y), num_parallel_calls=AUTOTUNE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_merged = train_ds_balanced.concatenate(train_ds_augmented)\n",
    "train_ds_merged = train_ds_merged.concatenate(train_ds_augmented2)\n",
    "# train_ds_merged = train_ds_merged.concatenate(train_ds_augmented3)\n",
    "# train_ds_merged = train_ds_merged.concatenate(train_ds_augmented4)\n",
    "\n",
    "train_ds_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "classes = [0, 1, 2, 3, 4]\n",
    "y = np.array([label.numpy() for _, label in train_ds_merged.unbatch()])\n",
    "y = np.argmax(y, axis=1)\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=classes, y=y)\n",
    "class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_weights_dict = {}\n",
    "for i, weight in enumerate(class_weights):\n",
    "    class_weights_dict[i] = weight\n",
    "class_weights_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = [0,1,2,3,4]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in train_ds_merged.take(4):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label_index = np.argmax(labels[i].numpy()) #\n",
    "        plt.title(class_names[int(label_index)])  \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds_merged = train_ds_merged.map(lambda x, y: (x/255, y))\n",
    "val_ds_balanced = val_ds_balanced.map(lambda x, y: (x/255, y))\n",
    "test_ds_balanced = test_ds_balanced.map(lambda x, y: (x/255, y))\n",
    "\n",
    "sample = val_ds_balanced.as_numpy_iterator().next()\n",
    "sample[0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, 7, activation=\"relu\", padding=\"same\", input_shape=(256, 256, 3)))\n",
    "model.add(MaxPooling2D(2))\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Conv2D(32, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Conv2D(16, 3, activation=\"relu\", padding=\"same\"))\n",
    "model.add(MaxPooling2D())\n",
    "model.add(Dropout(0.25))  \n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(256, activation=\"relu\"))\n",
    "model.add(Dropout(0.5))  \n",
    "\n",
    "model.add(Dense(units=5, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\"adam\", loss='categorical_crossentropy', metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from keras.callbacks import ModelCheckpoint, EarlyStopping, TensorBoard\n",
    "# callbacks = [\n",
    "#         EarlyStopping(patience=10, monitor=\"val_loss\", verbose=1),\n",
    "#         TensorBoard(log_dir=\"logs\", histogram_freq=1),\n",
    "#     ]\n",
    "# hist = model.fit(train_ds_merged, epochs=100, validation_data=val_ds_balanced, class_weight=class_weights_dict, callbacks=callbacks)\n",
    "model.load_weights('./checkpoints/my_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "true_labels = []\n",
    "predicted_labels = []\n",
    "\n",
    "for batch in test_ds_balanced:\n",
    "    X, y = batch\n",
    "    yhat = model.predict(X)\n",
    "    true_labels.extend(np.argmax(y, axis=1))\n",
    "    predicted_labels.extend(np.argmax(yhat, axis=1))\n",
    "\n",
    "accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "precision = precision_score(true_labels, predicted_labels, average='macro')\n",
    "recall = recall_score(true_labels, predicted_labels, average='macro')\n",
    "F1 = f1_score(true_labels, predicted_labels, average='macro')\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1: \", F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "conf_matrix = confusion_matrix(true_labels, predicted_labels)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(\n",
    "    conf_matrix,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=[\n",
    "        \"Chateau de Chenonceau\",\n",
    "        \"Dancing House\",\n",
    "        \"Hagia Sophia\",\n",
    "        \"St Basils Cathedral\",\n",
    "        \"The Colosseum\",\n",
    "    ],\n",
    "    yticklabels=[\n",
    "        \"Chateau de Chenonceau\",\n",
    "        \"Dancing House\",\n",
    "        \"Hagia Sophia\",\n",
    "        \"St Basils Cathedral\",\n",
    "        \"The Colosseum\",\n",
    "    ],\n",
    ")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# img = cv2.imread(\"st5.jpg\")\n",
    "# image_resized = tf.image.resize(img,(256,256))\n",
    "\n",
    "# print(np.expand_dims(image_resized/255,0).shape)\n",
    "# yhat = model.predict(np.expand_dims(image_resized/255,0))\n",
    "# print(yhat)\n",
    "\n",
    "# class_index = yhat.argmax(axis=1)\n",
    "# if class_index == 0:\n",
    "#     print(\"Chateau de Chenonceau\")\n",
    "# elif class_index == 1:\n",
    "#     print(\"Dancing House\")\n",
    "# elif class_index == 2:\n",
    "#     print(\"Hagia Sophia\")\n",
    "# elif class_index == 3:\n",
    "#     print(\"St Basils Cathedral\")\n",
    "# elif class_index == 4:\n",
    "#     print(\"The Colosseum\")\n",
    "\n",
    "# plt.imshow(image_resized.numpy().astype(int))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test ds ne sme biti normalizovan!\n",
    "class_names = [\"Chateau\", \"Dancing\", \"Hagia\", \"St Basils\", \"Colosseum\"]\n",
    "plt.figure(figsize=(10, 10))\n",
    "for images, labels in test_ds_balanced.take(1):\n",
    "    for i in range(9):\n",
    "        ax = plt.subplot(3, 3, i + 1)\n",
    "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
    "        label_index = np.argmax(model.predict(np.expand_dims(images[i],0))) #\n",
    "        plt.title(f\"PR: {class_names[int(label_index)]} -> ST: {class_names[np.argmax(labels[i].numpy())]}\")  \n",
    "        plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TSNE implementacija\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn import manifold\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "# data = tf.keras.utils.image_dataset_from_directory(\n",
    "#     \"images\",\n",
    "#     labels=\"inferred\",\n",
    "#     label_mode=\"categorical\",\n",
    "#     image_size=(256, 256),\n",
    "#     batch_size=32,   \n",
    "# )\n",
    "\n",
    "# Initialize lists to store features and targets\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "# Iterate through the dataset to collect features and targets\n",
    "for batch_features, batch_targets in data:\n",
    "    features.extend(batch_features.numpy())\n",
    "    targets.extend(batch_targets.numpy())\n",
    "\n",
    "# Convert the lists to numpy arrays\n",
    "features = np.array(features)\n",
    "targets = np.array(targets)\n",
    "targets = targets.astype(int)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.reshape(features.shape[0],-1)\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dimensionality reduction using t-SNE\n",
    "tsne = manifold.TSNE(\n",
    "    n_components=2,\n",
    ")\n",
    "# fit and transform\n",
    "mnist_tr = tsne.fit_transform(features)\n",
    "# transformed_data is a 2D numpy array of shape (30000, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.argmax(targets, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_tr.shape\n",
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe\n",
    "cps_df = pd.DataFrame(columns=['CP1', 'CP2', 'target'],\n",
    "                       data=np.column_stack((mnist_tr, \n",
    "                                            targets)))\n",
    "# cast targets column to int\n",
    "cps_df.loc[:, 'target'] = cps_df.target.astype(int)\n",
    "cps_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buildings_map = {\n",
    "    0: \"Chateau\",\n",
    "    1: \"Dancing\",\n",
    "    2: \"Hagia\",\n",
    "    3: \"St Basils\",\n",
    "    4: \"The Colosseum\",\n",
    "}\n",
    "# map targets to actual clothes for plotting\n",
    "cps_df.loc[:, \"target\"] = cps_df.target.map(buildings_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cps_df.target.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.FacetGrid(cps_df, hue=\"target\", height=6)\n",
    "grid.map(plt.scatter, 'CP1', 'CP2').add_legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spomenikEnv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
